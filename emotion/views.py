from django.shortcuts import render

from emotion.models import TrainingStatus
from emotion.utils.inference import predict
import json
import time
import threading
from collections import Counter
from datetime import datetime

import torch
import evaluate
from datasets import load_dataset
from transformers import (
    BertTokenizer,
    BertForSequenceClassification,
    Trainer,
    TrainingArguments,
    TrainerCallback
)
from django.http import JsonResponse, StreamingHttpResponse
from django.views.decorators.csrf import csrf_exempt

# å…¨å±€è®­ç»ƒçŠ¶æ€
training_status = {
    'is_training': False,
    'current_epoch': 0,
    'total_epochs': 0,
    'current_step': 0,
    'total_steps': 0,
    'train_loss': 0.0,
    'eval_loss': 0.0,
    'eval_f1': 0.0,
    'eval_accuracy': 0.0,
    'eval_recall': 0.0,
    'progress_percent': 0.0,
    'logs': [],
    'error_message': '',
    'final_metrics': {},
    'hyperparameters': {},
    'training_start_time': None,
    'training_end_time': None,
    'should_stop': False  # åœæ­¢æ ‡å¿—
}

# å…¨å±€å˜é‡å­˜å‚¨è®­ç»ƒå™¨å’Œæ¨¡å‹
current_trainer = None
tokenizer = None


def count_labels(ds):
    """ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ"""
    label_counts = Counter(ds['label'])
    return label_counts.get(0, 0), label_counts.get(1, 0)


def preprocess_function(examples):
    """æ•°æ®é¢„å¤„ç†å‡½æ•°"""
    global tokenizer
    return tokenizer(examples['text'], padding=True, truncation=True)


def eval_metric(eval_predict):
    """è¯„ä¼°æŒ‡æ ‡è®¡ç®—"""
    acc_metric = evaluate.load("accuracy")
    recall_metric = evaluate.load("recall")
    f1_metric = evaluate.load("f1")

    predictions, labels = eval_predict
    predictions = predictions.argmax(axis=-1)

    acc = acc_metric.compute(predictions=predictions, references=labels)
    rec = recall_metric.compute(predictions=predictions, references=labels)
    f1 = f1_metric.compute(predictions=predictions, references=labels)

    result = {}
    result.update(acc)
    result.update(rec)
    result.update(f1)
    return result


class TrainingProgressCallback(TrainerCallback):
    """è®­ç»ƒè¿›åº¦å›è°ƒç±»"""

    def __init__(self):
        super().__init__()
        self.step_count = 0

    def on_train_begin(self, args, state, control, **kwargs):
        """è®­ç»ƒå¼€å§‹æ—¶çš„å›è°ƒ"""
        global training_status
        training_status.update({
            'is_training': True,
            'training_start_time': datetime.now().isoformat(),
            'total_epochs': args.num_train_epochs,
            'total_steps': state.max_steps,
            'should_stop': False
        })
        training_status['logs'].append(f"ğŸš€ å¼€å§‹è®­ç»ƒï¼Œæ€»å…± {args.num_train_epochs} è½®ï¼Œ{state.max_steps} æ­¥")

    def on_train_end(self, args, state, control, **kwargs):
        """è®­ç»ƒç»“æŸæ—¶çš„å›è°ƒ"""
        global training_status
        training_status.update({
            'training_end_time': datetime.now().isoformat(),
            'progress_percent': 100.0
        })
        training_status['logs'].append("ğŸ è®­ç»ƒå®Œæˆï¼")

    def on_epoch_begin(self, args, state, control, **kwargs):
        """æ¯è½®å¼€å§‹æ—¶çš„å›è°ƒ"""
        global training_status
        training_status['current_epoch'] = int(state.epoch) + 1
        training_status['logs'].append(f"ğŸ“š å¼€å§‹ç¬¬ {training_status['current_epoch']} è½®è®­ç»ƒ")

    def on_step_end(self, args, state, control, **kwargs):
        """æ¯æ­¥ç»“æŸæ—¶çš„å›è°ƒ"""
        global training_status, current_trainer

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢è®­ç»ƒ
        if training_status['should_stop']:
            training_status['logs'].append("â¹ï¸ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢è®­ç»ƒ...")
            control.should_training_stop = True
            return

        self.step_count += 1
        training_status['current_step'] = self.step_count

        # æ›´æ–°è¿›åº¦ç™¾åˆ†æ¯”
        if training_status['total_steps'] > 0:
            progress = (self.step_count / training_status['total_steps']) * 100
            training_status['progress_percent'] = min(progress, 100.0)

        # è·å–æœ€æ–°çš„è®­ç»ƒæŸå¤±
        if len(state.log_history) > 0:
            last_log = state.log_history[-1]
            if 'loss' in last_log:
                training_status['train_loss'] = last_log['loss']

        # æ¯10æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
        if self.step_count % 10 == 0:
            training_status['logs'].append(
                f"ğŸ“Š æ­¥éª¤ {self.step_count}/{training_status['total_steps']}, "
                f"æŸå¤±: {training_status['train_loss']:.4f}"
            )

    def on_evaluate(self, args, state, control, logs=None, **kwargs):
        """è¯„ä¼°æ—¶çš„å›è°ƒ"""
        global training_status
        if logs:
            # æ›´æ–°è¯„ä¼°æŒ‡æ ‡
            training_status.update({
                'eval_loss': logs.get('eval_loss', 0.0),
                'eval_accuracy': logs.get('eval_accuracy', 0.0),
                'eval_recall': logs.get('eval_recall', 0.0),
                'eval_f1': logs.get('eval_f1', 0.0)
            })

            # æ·»åŠ è¯„ä¼°æ—¥å¿—
            training_status['logs'].append(
                f"ğŸ“ˆ è¯„ä¼°ç»“æœ - å‡†ç¡®ç‡: {logs.get('eval_accuracy', 0):.4f}, "
                f"F1: {logs.get('eval_f1', 0):.4f}, "
                f"å¬å›ç‡: {logs.get('eval_recall', 0):.4f}"
            )

@csrf_exempt
def train_model_async():
    """å¼‚æ­¥è®­ç»ƒæ¨¡å‹å‡½æ•°"""
    global training_status, current_trainer, tokenizer

    try:
        training_status['logs'].append("ğŸ“¦ æ­£åœ¨åŠ è½½æ•°æ®é›†...")

        # åŠ è½½æ•°æ®é›†
        dataset = load_dataset("lansinuote/ChnSentiCorp", cache_dir="data")
        train_dataset = dataset['train']
        valid_dataset = dataset['validation']
        test_dataset = dataset['test']

        training_status['logs'].append(
            f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ - è®­ç»ƒé›†: {len(train_dataset)}, éªŒè¯é›†: {len(valid_dataset)}, æµ‹è¯•é›†: {len(test_dataset)}")

        # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
        train_neg, train_pos = count_labels(train_dataset)
        valid_neg, valid_pos = count_labels(valid_dataset)
        training_status['logs'].append(f"ğŸ“Š è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ - è´Ÿæ ·æœ¬: {train_neg}, æ­£æ ·æœ¬: {train_pos}")
        training_status['logs'].append(f"ğŸ“Š éªŒè¯é›†æ ‡ç­¾åˆ†å¸ƒ - è´Ÿæ ·æœ¬: {valid_neg}, æ­£æ ·æœ¬: {valid_pos}")

        # åŠ è½½æ¨¡å‹å’Œtokenizer
        model_name = "bert-base-chinese"
        training_status['logs'].append(f"ğŸ¤– æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")

        tokenizer = BertTokenizer.from_pretrained(model_name)
        model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)

        training_status['logs'].append("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

        # æ•°æ®é¢„å¤„ç†
        training_status['logs'].append("ğŸ”„ æ­£åœ¨è¿›è¡Œæ•°æ®é¢„å¤„ç†...")
        encoded_datasets = dataset.map(preprocess_function, batched=True)
        training_status['logs'].append("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")

        # è®­ç»ƒå‚æ•°
        training_args = TrainingArguments(
            output_dir='./results',
            num_train_epochs=1,
            per_device_train_batch_size=8,
            per_device_eval_batch_size=16,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir='./logs',
            logging_steps=10,
            learning_rate=3e-5,
            metric_for_best_model="f1",
            eval_strategy="steps",
            save_strategy="steps",
            eval_steps=200,
            save_steps=200,
            load_best_model_at_end=True,
        )

        # è®°å½•è¶…å‚æ•°
        hyper_params = {
            "æ¨¡å‹": model.__class__.__name__,
            "éšè—å±‚å¤§å°": getattr(model.config, "hidden_size", "N/A"),
            "è®­ç»ƒ epoch": training_args.num_train_epochs,
            "è®­ç»ƒ batch_size": training_args.per_device_train_batch_size,
            "éªŒè¯ batch_size": training_args.per_device_eval_batch_size,
            "å­¦ä¹ ç‡": training_args.learning_rate,
            "å­¦ä¹ ç‡ warmâ€‘up æ­¥æ•°": training_args.warmup_steps,
            "æƒé‡è¡°å‡": training_args.weight_decay,
            "ä¼˜åŒ–å™¨": str(training_args.optim),
            "è®¾å¤‡": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU",
        }
        training_status['hyperparameters'] = hyper_params

        training_status['logs'].append("âš™ï¸ è®­ç»ƒå‚æ•°é…ç½®å®Œæˆ")
        for key, value in hyper_params.items():
            training_status['logs'].append(f"   {key}: {value}")

        # åˆ›å»ºè®­ç»ƒå™¨
        current_trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=encoded_datasets['train'],
            eval_dataset=encoded_datasets['validation'],
            compute_metrics=eval_metric,
            callbacks=[TrainingProgressCallback()],
        )

        training_status['logs'].append("ğŸƒâ€â™‚ï¸ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")

        # å¼€å§‹è®­ç»ƒ
        current_trainer.train()

        # å¦‚æœè®­ç»ƒè¢«æ‰‹åŠ¨åœæ­¢
        if training_status['should_stop']:
            training_status['logs'].append("â¹ï¸ è®­ç»ƒå·²æ‰‹åŠ¨åœæ­¢")
            return

        training_status['logs'].append("ğŸ“Š æ­£åœ¨è¯„ä¼°è®­ç»ƒé›†æ€§èƒ½...")

        # è¯„ä¼°è®­ç»ƒé›†
        train_metrics = current_trainer.evaluate(encoded_datasets["train"])
        train_result = {
            'accuracy': train_metrics['eval_accuracy'],
            'recall': train_metrics['eval_recall'],
            'f1': train_metrics['eval_f1']
        }

        training_status['logs'].append(
            f"ğŸ“ˆ è®­ç»ƒé›†ç»“æœ - å‡†ç¡®ç‡: {train_result['accuracy']:.4f}, "
            f"å¬å›ç‡: {train_result['recall']:.4f}, F1: {train_result['f1']:.4f}"
        )

        training_status['logs'].append("ğŸ“Š æ­£åœ¨è¯„ä¼°æµ‹è¯•é›†æ€§èƒ½...")

        # è¯„ä¼°æµ‹è¯•é›†
        test_metrics = current_trainer.evaluate(encoded_datasets["test"])
        test_result = {
            'accuracy': test_metrics['eval_accuracy'],
            'recall': test_metrics['eval_recall'],
            'f1': test_metrics['eval_f1']
        }

        training_status['logs'].append(
            f"ğŸ“ˆ æµ‹è¯•é›†ç»“æœ - å‡†ç¡®ç‡: {test_result['accuracy']:.4f}, "
            f"å¬å›ç‡: {test_result['recall']:.4f}, F1: {test_result['f1']:.4f}"
        )

        # ä¿å­˜æœ€ç»ˆç»“æœ
        training_status['final_metrics'] = {
            'train': train_result,
            'test': test_result
        }

        # ä¿å­˜æ¨¡å‹
        training_status['logs'].append("ğŸ’¾ æ­£åœ¨ä¿å­˜æ¨¡å‹...")
        current_trainer.save_model()
        tokenizer.save_pretrained(training_args.output_dir)
        training_status['logs'].append("âœ… æ¨¡å‹ä¿å­˜å®Œæˆ")

        training_status['logs'].append("ğŸ‰ è®­ç»ƒæµç¨‹å…¨éƒ¨å®Œæˆï¼")

        # ä¿å­˜è®­ç»ƒç»“æœ
        TrainingStatus.objects.all().delete()
        TrainingStatus.objects.create(**training_status)

    except Exception as e:
        error_msg = f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        training_status['error_message'] = error_msg
        training_status['logs'].append(f"âŒ {error_msg}")
        training_status['is_training'] = False
    finally:
        training_status['is_training'] = False
        training_status['progress_percent'] = 100.0


@csrf_exempt
def start_training(request):
    """å¼€å§‹è®­ç»ƒçš„APIç«¯ç‚¹"""
    global training_status

    if training_status['is_training']:
        return JsonResponse({
            'success': False,
            'message': 'æ¨¡å‹æ­£åœ¨è®­ç»ƒä¸­ï¼Œè¯·ç­‰å¾…å½“å‰è®­ç»ƒå®Œæˆ'
        })

    # é‡ç½®çŠ¶æ€
    training_status.update({
        'is_training': False,  # ä¼šåœ¨å›è°ƒä¸­è®¾ç½®ä¸ºTrue
        'current_epoch': 0,
        'total_epochs': 0,
        'current_step': 0,
        'total_steps': 0,
        'train_loss': 0.0,
        'eval_loss': 0.0,
        'eval_f1': 0.0,
        'eval_accuracy': 0.0,
        'eval_recall': 0.0,
        'progress_percent': 0.0,
        'logs': [],
        'error_message': '',
        'final_metrics': {},
        'hyperparameters': {},
        'training_start_time': None,
        'training_end_time': None,
        'should_stop': False
    })

    # åœ¨æ–°çº¿ç¨‹ä¸­å¯åŠ¨è®­ç»ƒ
    training_thread = threading.Thread(target=train_model_async)
    training_thread.daemon = True
    training_thread.start()

    return JsonResponse({
        'success': True,
        'message': 'è®­ç»ƒå·²å¼€å§‹'
    })

@csrf_exempt
def get_training_status(request):
    """è·å–è®­ç»ƒçŠ¶æ€çš„APIç«¯ç‚¹"""
    global training_status
    return JsonResponse(training_status)

@csrf_exempt
def training_stream(request):
    """æœåŠ¡å™¨å‘é€äº‹ä»¶(SSE)æµå¼ä¼ è¾“è®­ç»ƒçŠ¶æ€"""

    def json_default(obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return str(obj)

    def event_stream():
        global training_status
        last_step = -1
        last_log_count = 0

        while True:
            # åªæœ‰å½“çŠ¶æ€æ”¹å˜æ—¶æ‰å‘é€æ•°æ®
            current_step = training_status['current_step']
            current_log_count = len(training_status['logs'])

            if (current_step != last_step or
                    current_log_count != last_log_count or
                    not training_status['is_training']):
                yield f"data: {json.dumps(training_status, ensure_ascii=False, default=json_default)}\n\n"
                last_step = current_step
                last_log_count = current_log_count

            time.sleep(0.5)  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡

            # å¦‚æœè®­ç»ƒå®Œæˆï¼Œå‘é€å‡ æ¬¡ååœæ­¢
            if (not training_status['is_training'] and
                    training_status['progress_percent'] >= 100):
                for _ in range(5):  # å†å‘é€5æ¬¡ç¡®ä¿å‰ç«¯æ”¶åˆ°
                    yield f"data: {json.dumps(training_status, ensure_ascii=False)}\n\n"
                    time.sleep(0.5)
                break

    response = StreamingHttpResponse(
        event_stream(),
        content_type='text/event-stream'
    )
    response['Cache-Control'] = 'no-cache'
    response['Access-Control-Allow-Origin'] = '*'
    return response


@csrf_exempt
def stop_training(request):
    """åœæ­¢è®­ç»ƒçš„APIç«¯ç‚¹"""
    global training_status

    if training_status['is_training']:
        training_status['should_stop'] = True
        training_status['logs'].append("â¹ï¸ æ”¶åˆ°åœæ­¢è®­ç»ƒè¯·æ±‚ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
        return JsonResponse({
            'success': True,
            'message': 'åœæ­¢è®­ç»ƒè¯·æ±‚å·²å‘é€ï¼Œå½“å‰æ‰¹æ¬¡å®Œæˆåå°†åœæ­¢è®­ç»ƒ'
        })
    else:
        return JsonResponse({
            'success': False,
            'message': 'å½“å‰æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„è®­ç»ƒ'
        })

@csrf_exempt
def get_training_results(request):
    """è·å–è®­ç»ƒç»“æœçš„APIç«¯ç‚¹"""
    global training_status

    if not training_status['final_metrics']:
        if not TrainingStatus.objects.exists():
            return JsonResponse({
                'success': False,
                'message': 'è®­ç»ƒå°šæœªå®Œæˆæˆ–æ²¡æœ‰å¯ç”¨ç»“æœ'
            })
        else:
            training_status = TrainingStatus.objects.values().first()
            return JsonResponse({
                'success': True,
                'data': {
                    'final_metrics': training_status.final_metrics,
                    'hyperparameters': training_status.hyperparameters,
                    'training_start_time': training_status.training_start_time,
                    'training_end_time': training_status.training_end_time,
                    'total_steps': training_status.total_steps,
                    'total_epochs': training_status.total_epochs
                }
            })

    return JsonResponse({
        'success': True,
        'data': {
            'final_metrics': training_status['final_metrics'],
            'hyperparameters': training_status['hyperparameters'],
            'training_start_time': training_status['training_start_time'],
            'training_end_time': training_status['training_end_time'],
            'total_steps': training_status['total_steps'],
            'total_epochs': training_status['total_epochs']
        }
    })

# Create your views here.
@csrf_exempt
def index(request):
    return render(request, 'index.html')

@csrf_exempt
def inference(request):
    if request.method == 'GET':
        return render(request, 'blogs-2.html')

    data = json.loads(request.body)
    sentence = data.get('sentence', '')
    label, prob = predict(sentence)
    return JsonResponse({'label': label, 'prob': prob})

@csrf_exempt
def training(request):
    return render(request, 'service-page-2.html')


@csrf_exempt
def testing(request):
    return render(request, 'test.html')